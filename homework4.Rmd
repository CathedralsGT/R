---
title: "homework4"
author: "Qiyao Jiang"
date: "2025-06-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

1.  

```{r load_data}
library(tidyverse)
ckm_nodes <- read_csv("data/ckm_nodes.csv")
dim(ckm_nodes)
colnames(ckm_nodes)
ckm_network <- read.table("data/ckm_network.dat", header=F)
dim(ckm_network)
```

2.  

```{r data_cleaning}
mutate(ckm_nodes, doctor_id = row_number()) -> ckm_nodes
filter(ckm_nodes, !is.na(adoption_date)) -> ckm_nodes


any(is.na(ckm_nodes$adoption_date))


expanded_df <- ckm_nodes |>
  crossing(month = 1:17)

mutate(ckm_network, doctor_id = row_number()) -> ckm_network

ckm_network |>
  filter(row_number() %in% ckm_nodes$doctor_id) |>
  dplyr::select(doctor_id, everything()) ->ckm_network
```

2125 = 125 \* 17, 6: doctor_id & month & four_observations

```{r}
record <- expanded_df |>
  mutate(
    began_adoption = ifelse(month==adoption_date, T, F),
    whether_adopted_before = ifelse(month>adoption_date, T, F),
  ) |>
  dplyr::select(doctor_id, adoption_date, began_adoption, whether_adopted_before, month)

arrange(record, doctor_id)

record |>
  group_by(month) |>
  mutate(
    num_of_connection_b4 =  as.numeric(t(ckm_network[, doctor_id+1]) %*% whether_adopted_before),
    num_of_connection = as.numeric(t(ckm_network[, doctor_id+1]) %*% (whether_adopted_before + began_adoption)),
  ) |>
  dplyr::select(!adoption_date) |>
  dplyr::select(doctor_id, month, everything())-> record
arrange(record, doctor_id) ->record
head(record, 20)
```

3.(a)because the maximum number of connection of a doctor is 28(outlier), and 75% of doctors have a total connection number below 10, we don't have enough data to estimate the value of p_k and q_k for k\>21

```{r}
mutate(ckm_network, total_connection = rowSums(dplyr::select(ckm_network, !doctor_id))) -> ckm_network
```

```{r}
max(ckm_network$total_connection)
median(ckm_network$total_connection)
ggplot(ckm_network, aes(y=total_connection)) +
  geom_boxplot()
```

(b) 

```{r calculating probabilities}
record |>
  filter(whether_adopted_before==F) |>
  group_by(num_of_connection_b4) |>
  summarize(
    total = n(),
    freq = sum(began_adoption),
    p = freq/total
  ) -> p_k.df

record |>
  filter(whether_adopted_before==F) |>
  group_by(num_of_connection) |>
  summarize(
    total = n(),
    freq = sum(began_adoption),
    q = freq/total
  ) ->q_k.df

```

(c) 

```{r plot}
ggplot(p_k.df, aes(x=num_of_connection_b4, y=p)) +
  geom_point(alpha=0.7, size=2.5, color="steelblue") +
  labs(x="Number of connections before that month", y="Probability of adoption") +
  theme_bw()
ggplot(q_k.df, aes(x=num_of_connection, y=q)) +
  geom_point(alpha=0.7, size=2.5, color="purple") +
  labs(x="Number of connections exactly that month", y="Probability of adoption") +
  theme_bw()
```

4.  (a)linear model

```{r}
linear.model <- lm(p ~ num_of_connection_b4, p_k.df)
summary(linear.model)
```

the estimated intercept is 0.087, and estimated slope is 0.026; however the p-value is large(for slope it's 0.255\>0.05), which might be caused by those outlier data pionts which is generated by a rather small amount of sample number. Try to filter by "total \> 15":

```{r}
linear.model.beta <- lm(p ~ num_of_connection_b4, filter(p_k.df, total > 15))
summary(linear.model.beta)
```

now we have a p-value close to 0.05 and a R2 value of 0.56, suggesting that the number of connection is a not-bad predictor

(b)this advanced model tries to map p_k into a value between 0 and 1. we reformulate this formula into log(p/(1-p)) = a+b\*k to make it easier for model fitting

```{r}
logit.model <- lm(log(p/(1-p))~num_of_connection_b4, filter(p_k.df, total > 15))
summary(logit.model)
```

the result shows that the number of connection has a marginal significance(p-value=0.097\<0.1) to the variance of adoption rate

(c)plot

```{r predict}
new_data <- data.frame(num_of_connection_b4 = seq(from=min(p_k.df$num_of_connection_b4), to=max(p_k.df$num_of_connection_b4), length.out=200))
new_data$linear.pred.p <- predict(linear.model, newdata=new_data)
logit.pred <- predict(logit.model, newdata=new_data)
new_data$logit.pred.p <- exp(logit.pred)/(1+exp(logit.pred))
new_data |>
  pivot_longer(
    cols = c("linear.pred.p", "logit.pred.p"),
    names_to = "model",
    values_to = "p"
  ) -> new_data
```

```{r plot_2}
ggplot(p_k.df, aes(x=num_of_connection_b4, y=p)) +
  geom_point(alpha=0.7, size=2.5, color="steelblue") +
  geom_line(data=new_data, aes(x=num_of_connection_b4, y=p, color=model), linewidth=0.75) +
  labs(x="Number of connection", y="Probability of adoption", title="Relationship between p_k and connection number", color="model type") +
  theme_bw()
```

I would prefer the logit model, as it only outputs a predicted p-value between 0 and 1, so it's capable of scaling to large connection numbers.
